{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (0.3.23)\n",
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (1.71.0)\n",
      "Requirement already satisfied: neo4j-driver in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (5.28.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: neo4j in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (5.28.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (0.3.26)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (2.11.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: pytz in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from neo4j-driver) (2025.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_community in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (0.3.51)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_openai in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_openai) (0.3.51)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_openai) (1.71.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.3.26)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_openai) (2.11.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.49->langchain_openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.49->langchain_openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pypdf in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (5.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-experimental in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-experimental) (0.3.21)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-experimental) (0.3.51)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.26)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (2.11.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.23->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.8)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/chatbot_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary dependencies\n",
    "%pip install langchain openai neo4j-driver python-dotenv neo4j\n",
    "%pip install langchain_community\n",
    "%pip install langchain_openai\n",
    "%pip install pypdf\n",
    "%pip install python-dotenv\n",
    "%pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import warnings\n",
    "# from typing import List, Optional, Any, Dict\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# from langchain_core.documents import Document\n",
    "# from pydantic import BaseModel, Field\n",
    "# from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# # Suppress specific warnings from langchain_experimental\n",
    "# warnings.filterwarnings(\n",
    "#     \"ignore\",\n",
    "#     message=\"Importing LLMGraphTransformer from langchain_experimental.graph_transformers is deprecated\",\n",
    "#     category=UserWarning\n",
    "# )\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Note: 'gpt-4o-2024-11-20' might not be a valid model name.\n",
    "# # Using 'gpt-4o' which is the latest generally available version as of mid-2024.\n",
    "# # Ensure your API key has access to this model.\n",
    "# LLM_MODEL_NAME = \"gpt-4o\"\n",
    "# EMBEDDING_MODEL_NAME = \"text-embedding-3-small\" # Or another OpenAI embedding model\n",
    "# # Define the types of entities and relationships you want to extract (optional but recommended)\n",
    "# # If None, the LLM will try to infer them.\n",
    "# ALLOWED_NODES = [\"Person\", \"Organization\", \"Location\", \"Concept\", \"Event\", \"Document\"]\n",
    "# ALLOWED_RELATIONSHIPS = [\"CONNECTS\", \"MENTIONS\", \"LOCATED_IN\", \"PART_OF\", \"RELATED_TO\", \"AUTHOR_OF\", \"REFERENCES\"]\n",
    "\n",
    "# # --- Pydantic Models for Structured Output (Used internally by LLMGraphTransformer) ---\n",
    "# # These help structure the LLM's output but you primarily interact with the GraphDocument object\n",
    "\n",
    "# class Node(BaseModel):\n",
    "#     \"\"\"Represents a node in the graph.\"\"\"\n",
    "#     id: str = Field(description=\"Unique identifier for the node (e.g., entity name)\")\n",
    "#     type: str = Field(description=\"Type of the node (e.g., Person, Organization)\")\n",
    "#     properties: Optional[Dict[str, Any]] = Field(\n",
    "#         description=\"Additional properties associated with the node\", default_factory=dict\n",
    "#     )\n",
    "\n",
    "# class Relationship(BaseModel):\n",
    "#     \"\"\"Represents a relationship between two nodes in the graph.\"\"\"\n",
    "#     source: Node = Field(description=\"The source node of the relationship\")\n",
    "#     target: Node = Field(description=\"The target node of the relationship\")\n",
    "#     type: str = Field(description=\"The type of the relationship (e.g., CONNECTS, MENTIONS)\")\n",
    "#     properties: Optional[Dict[str, Any]] = Field(\n",
    "#         description=\"Additional properties associated with the relationship\", default_factory=dict\n",
    "#     )\n",
    "\n",
    "# class KnowledgeGraph(BaseModel):\n",
    "#     \"\"\"Represents the structured knowledge graph extracted from a text chunk.\"\"\"\n",
    "#     nodes: List[Node] = Field(description=\"List of nodes in the graph\")\n",
    "#     relationships: List[Relationship] = Field(description=\"List of relationships in the graph\")\n",
    "\n",
    "# # --- Core Functions ---\n",
    "\n",
    "# def check_openai_connection(api_key: str, model_name: str) -> bool:\n",
    "#     \"\"\"Checks if the OpenAI API key and model are accessible.\"\"\"\n",
    "#     print(f\"Attempting to connect to OpenAI with model: {model_name}...\")\n",
    "#     try:\n",
    "#         llm = ChatOpenAI(openai_api_key=api_key, model=model_name, temperature=0)\n",
    "#         # Simple test invocation\n",
    "#         llm.invoke(\"Hello!\")\n",
    "#         print(\"OpenAI connection successful.\")\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error connecting to OpenAI or accessing model '{model_name}': {e}\")\n",
    "#         print(\"Please check your API key, model access permissions, and network connection.\")\n",
    "#         return False\n",
    "\n",
    "# def process_file(file_path: str, llm: ChatOpenAI, embeddings_model: OpenAIEmbeddings) -> List[Document]:\n",
    "#     \"\"\"\n",
    "#     Loads, splits, embeds, and extracts graph data from a text or PDF file.\n",
    "\n",
    "#     Args:\n",
    "#         file_path: Path to the input file (.txt or .pdf).\n",
    "#         llm: Initialized ChatOpenAI model for extraction.\n",
    "#         embeddings_model: Initialized OpenAIEmbeddings model.\n",
    "\n",
    "#     Returns:\n",
    "#         A list of LangChain GraphDocument objects, each representing the\n",
    "#         extracted graph structure from a chunk of the original document.\n",
    "#         Note: Embeddings are created internally if needed by the transformer\n",
    "#               but the primary output here is the structured graph data.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\nProcessing file: {file_path}...\")\n",
    "#     file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "#     if file_extension == \".txt\":\n",
    "#         loader = TextLoader(file_path, encoding='utf-8')\n",
    "#     elif file_extension == \".pdf\":\n",
    "#         loader = PyPDFLoader(file_path)\n",
    "#     else:\n",
    "#         print(f\"Unsupported file type: {file_extension}. Skipping.\")\n",
    "#         return []\n",
    "\n",
    "#     try:\n",
    "#         documents = loader.load() # Loads and potentially splits based on loader (PDF often splits by page)\n",
    "#         print(f\"Loaded {len(documents)} initial document sections.\")\n",
    "\n",
    "#         # Using LLMGraphTransformer to handle chunking and extraction\n",
    "#         # It uses the LLM to identify nodes and relationships based on the text.\n",
    "#         graph_transformer = LLMGraphTransformer(\n",
    "#             llm=llm,\n",
    "#             allowed_nodes=ALLOWED_NODES,               # Optional: Guide the LLM\n",
    "#             allowed_relationships=ALLOWED_RELATIONSHIPS, # Optional: Guide the LLM\n",
    "#             prompt=None # Use default prompt or provide a custom one\n",
    "#         )\n",
    "\n",
    "#         print(\"Extracting graph structure from documents...\")\n",
    "#         # This is the core step: converts text documents into graph documents\n",
    "#         graph_documents = graph_transformer.convert_to_graph_documents(documents)\n",
    "#         print(f\"Extracted {len(graph_documents)} graph documents.\")\n",
    "\n",
    "#         # Note: Embeddings are not explicitly added to the output here,\n",
    "#         # as the primary goal was entity/relationship extraction for Memgraph.\n",
    "#         # The transformer might use embeddings internally if configured,\n",
    "#         # but the returned GraphDocument focuses on nodes and relationships.\n",
    "#         # If you need chunk text + embedding + graph, you'd need a more manual loop.\n",
    "\n",
    "#         return graph_documents\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing file {file_path}: {e}\")\n",
    "#         return []\n",
    "\n",
    "# # --- Main Execution ---\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#     if not api_key:\n",
    "#         print(\"Error: OPENAI_API_KEY not found in environment variables.\")\n",
    "#         exit(1)\n",
    "\n",
    "#     # 1. Check OpenAI Connection First\n",
    "#     if not check_openai_connection(api_key, LLM_MODEL_NAME):\n",
    "#         exit(1) # Stop if connection fails\n",
    "\n",
    "#     # 2. Initialize models (only after successful connection check)\n",
    "#     llm = ChatOpenAI(openai_api_key=api_key, model=LLM_MODEL_NAME, temperature=0)\n",
    "#     embeddings = OpenAIEmbeddings(openai_api_key=api_key, model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "#     # 3. Define input file path (replace with your file)\n",
    "#     # input_file = \"path/to/your/document.txt\"\n",
    "#     input_file = \"/Users/ryangichuru/Downloads/AI Group Project/other/resources/Need Help in a Crisis 2025 (1).pdf\" # Or your PDF file\n",
    "\n",
    "#     if not os.path.exists(input_file):\n",
    "#         print(f\"Error: Input file not found at {input_file}\")\n",
    "#         exit(1)\n",
    "\n",
    "#     # 4. Process the file\n",
    "#     processed_graph_data = process_file(input_file, llm, embeddings)\n",
    "\n",
    "#     # 5. Display results (example: print nodes and relationships for the first graph doc)\n",
    "#     if processed_graph_data:\n",
    "#         print(\"\\n--- Example Extracted Graph Data (First Chunk) ---\")\n",
    "#         first_graph_doc = processed_graph_data[0]\n",
    "\n",
    "#         print(\"\\nNodes:\")\n",
    "#         for node in first_graph_doc.nodes:\n",
    "#             print(f\"  ID: {node.id}, Type: {node.type}, Properties: {node.properties}\")\n",
    "\n",
    "#         print(\"\\nRelationships:\")\n",
    "#         for rel in first_graph_doc.relationships:\n",
    "#             print(f\"  Source: {rel.source.id} ({rel.source.type})\")\n",
    "#             print(f\"  Target: {rel.target.id} ({rel.target.type})\")\n",
    "#             print(f\"  Type: {rel.type}\")\n",
    "#             print(f\"  Properties: {rel.properties}\")\n",
    "#             print(\"-\" * 10)\n",
    "\n",
    "#         print(f\"\\nSuccessfully processed file. Found {len(processed_graph_data)} graph segments.\")\n",
    "#         # You would typically save this structured data (e.g., to JSON)\n",
    "#         # for later ingestion into Memgraph using Cypher queries.\n",
    "#     else:\n",
    "#         print(\"No graph data extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory: /Users/ryangichuru/Downloads/AI Group Project/other/resources\n",
      "Output directory: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data\n",
      "Attempting to connect to OpenAI with model: gpt-4o...\n",
      "OpenAI connection successful.\n",
      "\n",
      "Found 6 files to process.\n",
      "\n",
      "Processing file: Selp help resources.txt...\n",
      "Loaded 1 initial document sections from Selp help resources.txt.\n",
      "Extracting graph structure from Selp help resources.txt using custom prompt...\n",
      "Extracted 1 graph documents from Selp help resources.txt.\n",
      "Successfully saved extracted data for Selp help resources.txt to /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Selp help resources.json\n",
      "\n",
      "Processing file: Uni Mental health day resources.txt...\n",
      "Loaded 1 initial document sections from Uni Mental health day resources.txt.\n",
      "Extracting graph structure from Uni Mental health day resources.txt using custom prompt...\n",
      "Extracted 1 graph documents from Uni Mental health day resources.txt.\n",
      "Successfully saved extracted data for Uni Mental health day resources.txt to /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Uni Mental health day resources.json\n",
      "\n",
      "Processing file: Mental health blogs.txt...\n",
      "Loaded 1 initial document sections from Mental health blogs.txt.\n",
      "Extracting graph structure from Mental health blogs.txt using custom prompt...\n",
      "Extracted 1 graph documents from Mental health blogs.txt.\n",
      "Successfully saved extracted data for Mental health blogs.txt to /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Mental health blogs.json\n",
      "\n",
      "Processing file: Councelling FAQs.txt...\n",
      "Loaded 1 initial document sections from Councelling FAQs.txt.\n",
      "Extracting graph structure from Councelling FAQs.txt using custom prompt...\n",
      "Extracted 1 graph documents from Councelling FAQs.txt.\n",
      "Successfully saved extracted data for Councelling FAQs.txt to /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Councelling FAQs.json\n",
      "\n",
      "Processing file: Councellors Corner.txt...\n",
      "Loaded 1 initial document sections from Councellors Corner.txt.\n",
      "Extracting graph structure from Councellors Corner.txt using custom prompt...\n",
      "Extracted 1 graph documents from Councellors Corner.txt.\n",
      "Successfully saved extracted data for Councellors Corner.txt to /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Councellors Corner.json\n",
      "\n",
      "Processing file: Need Help in a Crisis 2025 (1).pdf...\n",
      "Loaded 4 initial document sections from Need Help in a Crisis 2025 (1).pdf.\n",
      "Extracting graph structure from Need Help in a Crisis 2025 (1).pdf using custom prompt...\n",
      "Extracted 4 graph documents from Need Help in a Crisis 2025 (1).pdf.\n",
      "Successfully saved extracted data for Need Help in a Crisis 2025 (1).pdf to /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Need Help in a Crisis 2025 (1).json\n",
      "\n",
      "--- Processing Complete ---\n"
     ]
    }
   ],
   "source": [
    "# /Users/ryangichuru/Downloads/AI Group Project/other/data_extractor.ipynb\n",
    "import os\n",
    "import warnings\n",
    "from typing import List, Optional, Any, Dict\n",
    "import json\n",
    "from pathlib import Path\n",
    "import traceback # Import traceback for better error logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "# Updated Pydantic imports for v2 compatibility\n",
    "from pydantic import BaseModel, Field, field_validator # Changed validator to field_validator\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Importing LLMGraphTransformer from langchain_experimental.graph_transformers is deprecated\",\n",
    "    category=UserWarning\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*LangChain uses pydantic v2 internally.*\",\n",
    "    category=UserWarning\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Pydantic V1 style `@validator` validators are deprecated.*\",\n",
    "    category=DeprecationWarning # Pydantic uses DeprecationWarning for this\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*you should migrate to Pydantic V2 style `@field_validator` validators.*\",\n",
    "    category=DeprecationWarning # Pydantic uses DeprecationWarning for this\n",
    ")\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "LLM_MODEL_NAME = \"gpt-4o\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"\n",
    "ALLOWED_NODES = [\"Person\", \"Organization\", \"Location\", \"Concept\", \"Event\", \"Document\", \"Service\", \"Condition\", \"Guidance\", \"Resource\", \"Contact\"]\n",
    "ALLOWED_RELATIONSHIPS = [\"CONNECTS\", \"MENTIONS\", \"LOCATED_IN\", \"PART_OF\", \"RELATED_TO\", \"AUTHOR_OF\", \"REFERENCES\", \"PROVIDES\", \"HELPS_WITH\", \"CONTACT_FOR\", \"OFFERS\"]\n",
    "\n",
    "# --- Custom Prompt Template String ---\n",
    "# Removed the literal {} from the instructions text.\n",
    "CUSTOM_PROMPT_TEMPLATE_STR = \"\"\"\n",
    "Extract entities and relationships from the text below based on the provided schema.\n",
    "\n",
    "Instructions:\n",
    "1. Identify entities (nodes) and relationships relevant to the allowed types.\n",
    "2. For each node, provide its 'id' (unique name/identifier), 'type', and a 'properties' dictionary containing relevant attributes found in the text (e.g., for a 'Service', extract 'phone_number', 'website'; for a 'Location', extract 'address'). If no properties are found, the value for 'properties' MUST be an empty JSON dictionary.\n",
    "3. For each relationship, provide its 'source' node 'id', 'target' node 'id', 'type', and a 'properties' dictionary describing the relationship (e.g., for 'CONTACT_FOR', specify the contact detail if it's part of the relationship context). If no properties are found, the value for 'properties' MUST be an empty JSON dictionary.\n",
    "4. Ensure node 'id' values are consistent across the graph. If an entity is mentioned multiple times, use the same 'id'.\n",
    "5. Output ONLY a valid JSON object containing two keys: 'nodes' and 'relationships'. The value for each key should be a list of the extracted nodes/relationships. Adhere strictly to the JSON format. Do not include explanations or markdown formatting.\n",
    "\n",
    "Permitted Node Types:\n",
    "{node_labels}\n",
    "\n",
    "Permitted Relationship Types:\n",
    "{rel_labels}\n",
    "\n",
    "Text:\n",
    "{input}\n",
    "\n",
    "JSON Output:\n",
    "\"\"\"\n",
    "\n",
    "# --- Pydantic Models for Structured Output ---\n",
    "\n",
    "class Node(BaseModel):\n",
    "    \"\"\"Represents a node in the graph.\"\"\"\n",
    "    id: str = Field(description=\"Unique identifier for the node (e.g., entity name or concept)\")\n",
    "    type: str = Field(description=\"Type of the node (e.g., Person, Organization, Concept)\")\n",
    "    properties: Optional[Dict[str, Any]] = Field(\n",
    "        description=\"Additional properties associated with the node\", default_factory=dict\n",
    "    )\n",
    "\n",
    "    @field_validator('properties', mode='before')\n",
    "    @classmethod\n",
    "    def set_properties_default(cls, v):\n",
    "        return v or {}\n",
    "\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Represents a relationship between two nodes in the graph.\"\"\"\n",
    "    source: Node = Field(description=\"The source node of the relationship\")\n",
    "    target: Node = Field(description=\"The target node of the relationship\")\n",
    "    type: str = Field(description=\"The type of the relationship (e.g., CONNECTS, MENTIONS)\")\n",
    "    properties: Optional[Dict[str, Any]] = Field(\n",
    "        description=\"Additional properties associated with the relationship\", default_factory=dict\n",
    "    )\n",
    "\n",
    "    @field_validator('properties', mode='before')\n",
    "    @classmethod\n",
    "    def set_properties_default(cls, v):\n",
    "        return v or {}\n",
    "\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Represents the structured knowledge graph extracted from a text chunk.\"\"\"\n",
    "    nodes: List[Node] = Field(description=\"List of nodes in the graph\")\n",
    "    relationships: List[Relationship] = Field(description=\"List of relationships in the graph\")\n",
    "\n",
    "\n",
    "# --- Core Functions ---\n",
    "\n",
    "def check_openai_connection(api_key: str, model_name: str) -> bool:\n",
    "    \"\"\"Checks if the OpenAI API key and model are accessible.\"\"\"\n",
    "    print(f\"Attempting to connect to OpenAI with model: {model_name}...\")\n",
    "    try:\n",
    "        llm = ChatOpenAI(openai_api_key=api_key, model=model_name, temperature=0)\n",
    "        llm.invoke(\"Hello!\")\n",
    "        print(\"OpenAI connection successful.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to OpenAI or accessing model '{model_name}': {e}\")\n",
    "        print(\"Please check your API key, model access permissions, and network connection.\")\n",
    "        return False\n",
    "\n",
    "def process_file(file_path: Path, llm: ChatOpenAI, embeddings_model: OpenAIEmbeddings) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads, splits, embeds, and extracts graph data from a text or PDF file.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path object for the input file (.txt or .pdf).\n",
    "        llm: Initialized ChatOpenAI model for extraction.\n",
    "        embeddings_model: Initialized OpenAIEmbeddings model.\n",
    "\n",
    "    Returns:\n",
    "        A list of LangChain GraphDocument objects.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing file: {file_path.name}...\")\n",
    "    file_extension = file_path.suffix.lower()\n",
    "\n",
    "    if file_extension == \".txt\":\n",
    "        loader = TextLoader(str(file_path), encoding='utf-8')\n",
    "    elif file_extension == \".pdf\":\n",
    "        loader = PyPDFLoader(str(file_path))\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {file_extension}. Skipping.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        documents = loader.load()\n",
    "        if not documents:\n",
    "             print(f\"No content loaded from {file_path.name}. Skipping.\")\n",
    "             return []\n",
    "        print(f\"Loaded {len(documents)} initial document sections from {file_path.name}.\")\n",
    "\n",
    "        # Format the prompt string dynamically\n",
    "        formatted_prompt_str = CUSTOM_PROMPT_TEMPLATE_STR.format(\n",
    "            node_labels=\", \".join(ALLOWED_NODES),\n",
    "            rel_labels=\", \".join(ALLOWED_RELATIONSHIPS),\n",
    "            input=\"{input}\" # Keep placeholder for transformer\n",
    "        )\n",
    "        # Create the prompt template *after* formatting with node/rel labels\n",
    "        dynamic_prompt = ChatPromptTemplate.from_template(formatted_prompt_str)\n",
    "\n",
    "\n",
    "        # Initialize the transformer\n",
    "        graph_transformer = LLMGraphTransformer(\n",
    "            llm=llm,\n",
    "            allowed_nodes=ALLOWED_NODES,\n",
    "            allowed_relationships=ALLOWED_RELATIONSHIPS,\n",
    "            prompt=dynamic_prompt, # Use the dynamically formatted prompt\n",
    "            node_properties=True,\n",
    "            relationship_properties=True,\n",
    "            strict_mode=True\n",
    "        )\n",
    "\n",
    "        print(f\"Extracting graph structure from {file_path.name} using custom prompt...\")\n",
    "        if documents:\n",
    "            graph_documents = graph_transformer.convert_to_graph_documents(documents)\n",
    "            print(f\"Extracted {len(graph_documents)} graph documents from {file_path.name}.\")\n",
    "            # Filter out potentially empty graph documents if the LLM fails on a chunk\n",
    "            valid_graph_documents = [gd for gd in graph_documents if gd.nodes or gd.relationships]\n",
    "            if len(valid_graph_documents) < len(graph_documents):\n",
    "                print(f\"Filtered out {len(graph_documents) - len(valid_graph_documents)} empty graph document(s).\")\n",
    "            return valid_graph_documents\n",
    "        else:\n",
    "            print(f\"No documents to process for {file_path.name}.\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path.name} ({type(e).__name__}): {e}\")\n",
    "        traceback.print_exc() # Print the full traceback for debugging\n",
    "        return []\n",
    "\n",
    "def graph_document_to_dict(graph_doc: Document) -> Dict:\n",
    "    \"\"\"Converts a GraphDocument to a JSON-serializable dictionary.\"\"\"\n",
    "    nodes_list = getattr(graph_doc, 'nodes', [])\n",
    "    relationships_list = getattr(graph_doc, 'relationships', [])\n",
    "    metadata = getattr(graph_doc, 'metadata', {})\n",
    "\n",
    "    serializable_nodes = []\n",
    "    for node in nodes_list:\n",
    "        try:\n",
    "            serializable_nodes.append(node.model_dump())\n",
    "        except Exception as dump_error:\n",
    "             print(f\"Warning: Could not serialize node: {node}. Error: {dump_error}\")\n",
    "\n",
    "    serializable_relationships = []\n",
    "    for rel in relationships_list:\n",
    "        try:\n",
    "            dumped_rel = rel.model_dump()\n",
    "            if isinstance(dumped_rel.get(\"source\"), BaseModel):\n",
    "                 dumped_rel[\"source\"] = dumped_rel[\"source\"].model_dump()\n",
    "            if isinstance(dumped_rel.get(\"target\"), BaseModel):\n",
    "                 dumped_rel[\"target\"] = dumped_rel[\"target\"].model_dump()\n",
    "            serializable_relationships.append(dumped_rel)\n",
    "        except Exception as dump_error:\n",
    "            print(f\"Warning: Could not serialize relationship: {rel}. Error: {dump_error}\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"metadata\": metadata,\n",
    "        \"nodes\": serializable_nodes,\n",
    "        \"relationships\": serializable_relationships\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"Error: OPENAI_API_KEY not found in environment variables.\")\n",
    "        exit(1)\n",
    "\n",
    "    base_dir = Path(\"/Users/ryangichuru/Downloads/AI Group Project/other/resources\")\n",
    "    input_dir = base_dir\n",
    "    output_dir = base_dir / \"json_data\"\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "    if not check_openai_connection(api_key, LLM_MODEL_NAME):\n",
    "        exit(1)\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=api_key, model=LLM_MODEL_NAME, temperature=0)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key, model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    files_to_process = list(input_dir.glob('*.txt')) + list(input_dir.glob('*.pdf'))\n",
    "\n",
    "    if not files_to_process:\n",
    "        print(f\"No .txt or .pdf files found in {input_dir}\")\n",
    "        exit(0)\n",
    "\n",
    "    print(f\"\\nFound {len(files_to_process)} files to process.\")\n",
    "\n",
    "    for file_path in files_to_process:\n",
    "        processed_graph_data_list = process_file(file_path, llm, embeddings)\n",
    "\n",
    "        if processed_graph_data_list:\n",
    "            output_filename = output_dir / f\"{file_path.stem}.json\"\n",
    "            output_data = [graph_document_to_dict(graph_doc) for graph_doc in processed_graph_data_list]\n",
    "            output_data = [item for item in output_data if item.get(\"nodes\") or item.get(\"relationships\")]\n",
    "\n",
    "            if not output_data:\n",
    "                 print(f\"No valid graph data extracted and converted for {file_path.name}. No JSON file created.\")\n",
    "                 continue\n",
    "\n",
    "            try:\n",
    "                with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"Successfully saved extracted data for {file_path.name} to {output_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving JSON for {file_path.name}: {e}\")\n",
    "        else:\n",
    "            print(f\"No graph data extracted for {file_path.name} after processing. No JSON file created.\")\n",
    "\n",
    "    print(\"\\n--- Processing Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Memgraph at bolt://localhost:7687...\n",
      "Memgraph connection successful.\n",
      "\n",
      "Found 6 JSON files to import.\n",
      "Reading JSON file: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Need Help in a Crisis 2025 (1).json...\n",
      "Deserializing 4 graph chunks from JSON...\n",
      "Importing 4 graph documents into Memgraph...\n",
      "Import successful for Need Help in a Crisis 2025 (1).json!\n",
      "Reading JSON file: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Selp help resources.json...\n",
      "Deserializing 1 graph chunks from JSON...\n",
      "Importing 1 graph documents into Memgraph...\n",
      "Import successful for Selp help resources.json!\n",
      "Reading JSON file: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Councelling FAQs.json...\n",
      "Deserializing 1 graph chunks from JSON...\n",
      "Importing 1 graph documents into Memgraph...\n",
      "Import successful for Councelling FAQs.json!\n",
      "Reading JSON file: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Councellors Corner.json...\n",
      "Deserializing 1 graph chunks from JSON...\n",
      "Importing 1 graph documents into Memgraph...\n",
      "Import successful for Councellors Corner.json!\n",
      "Reading JSON file: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Mental health blogs.json...\n",
      "Deserializing 1 graph chunks from JSON...\n",
      "Importing 1 graph documents into Memgraph...\n",
      "Import successful for Mental health blogs.json!\n",
      "Reading JSON file: /Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data/Uni Mental health day resources.json...\n",
      "Deserializing 1 graph chunks from JSON...\n",
      "Importing 1 graph documents into Memgraph...\n",
      "Import successful for Uni Mental health day resources.json!\n",
      "\n",
      "--- Import Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Make sure these imports are at the top of your script/cell ---\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.graphs import MemgraphGraph\n",
    "# Use GraphDocument for the import\n",
    "from langchain_community.graphs.graph_document import GraphDocument, Node as LangChainNode, Relationship as LangChainRelationship\n",
    "from langchain_core.documents import Document # Keep for source reference\n",
    "# Import your Pydantic models (make sure they match the ones used in data_extractor.ipynb)\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "# --- Pydantic Models (Should match data_extractor.ipynb) ---\n",
    "# These are used for deserializing the JSON\n",
    "class Node(BaseModel):\n",
    "    \"\"\"Represents a node in the graph.\"\"\"\n",
    "    id: str = Field(description=\"Unique identifier for the node\")\n",
    "    type: str = Field(description=\"Type of the node\")\n",
    "    properties: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    @field_validator('properties', mode='before')\n",
    "    @classmethod\n",
    "    def set_properties_default(cls, v):\n",
    "        return v or {}\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Represents a relationship between two nodes.\"\"\"\n",
    "    source: Node = Field(description=\"The source node\")\n",
    "    target: Node = Field(description=\"The target node\")\n",
    "    type: str = Field(description=\"Type of the relationship\")\n",
    "    properties: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    @field_validator('properties', mode='before')\n",
    "    @classmethod\n",
    "    def set_properties_default(cls, v):\n",
    "        return v or {}\n",
    "\n",
    "# Helper to structure the data read from JSON\n",
    "class GraphChunk(BaseModel):\n",
    "     metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "     nodes: List[Node]\n",
    "     relationships: List[Relationship]\n",
    "\n",
    "\n",
    "# --- Main Import Function (Updated) ---\n",
    "def import_json_to_memgraph(json_file_path: Path, graph: MemgraphGraph):\n",
    "    \"\"\"Reads the extracted JSON and imports it into Memgraph.\"\"\"\n",
    "    print(f\"Reading JSON file: {json_file_path}...\")\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            data_from_json = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {json_file_path}\")\n",
    "        return\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from {json_file_path}: {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred reading {json_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if not isinstance(data_from_json, list):\n",
    "        print(f\"Error: Expected a list of graph chunks in {json_file_path}, but got {type(data_from_json)}\")\n",
    "        return\n",
    "\n",
    "    graph_documents_to_add: List[GraphDocument] = [] # Correct type hint\n",
    "\n",
    "    print(f\"Deserializing {len(data_from_json)} graph chunks from JSON...\")\n",
    "    for i, chunk_data in enumerate(data_from_json):\n",
    "        try:\n",
    "            # Use Pydantic to parse and validate the chunk data from JSON\n",
    "            graph_chunk = GraphChunk.model_validate(chunk_data)\n",
    "\n",
    "            # Convert Pydantic Nodes/Relationships to LangChain versions\n",
    "            lc_nodes = [LangChainNode(id=n.id, type=n.type, properties=n.properties) for n in graph_chunk.nodes]\n",
    "            lc_relationships = [\n",
    "                LangChainRelationship(\n",
    "                    source=LangChainNode(id=r.source.id, type=r.source.type, properties=r.source.properties),\n",
    "                    target=LangChainNode(id=r.target.id, type=r.target.type, properties=r.target.properties),\n",
    "                    type=r.type,\n",
    "                    properties=r.properties\n",
    "                ) for r in graph_chunk.relationships\n",
    "            ]\n",
    "\n",
    "            # Create a source Document (optional but good practice for provenance)\n",
    "            source_doc = Document(page_content=\"\", metadata=graph_chunk.metadata) # Use an empty page_content\n",
    "\n",
    "            # Create the GraphDocument object expected by add_graph_documents\n",
    "            graph_doc = GraphDocument(\n",
    "                nodes=lc_nodes,\n",
    "                relationships=lc_relationships,\n",
    "                source=source_doc # Link back to the source metadata\n",
    "            )\n",
    "            graph_documents_to_add.append(graph_doc)\n",
    "\n",
    "        except Exception as validation_error: # Catch validation or other errors here\n",
    "            print(f\"Warning: Skipping chunk {i} due to validation/parsing error: {validation_error}\")\n",
    "            # Optionally log the problematic chunk_data for debugging\n",
    "            # import logging\n",
    "            # logging.warning(f\"Problematic data in chunk {i} of {json_file_path.name}: {chunk_data}\", exc_info=True)\n",
    "            continue # Skip to the next chunk\n",
    "\n",
    "    if not graph_documents_to_add:\n",
    "        print(\"No valid graph documents to import after deserialization.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Importing {len(graph_documents_to_add)} graph documents into Memgraph...\")\n",
    "    try:\n",
    "        # This is the core LangChain step for importing\n",
    "        graph.add_graph_documents(\n",
    "            graph_documents_to_add,\n",
    "            # include_source_info=True # Set to True if you want Document metadata stored as node properties\n",
    "        )\n",
    "        print(f\"Import successful for {json_file_path.name}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Memgraph import for {json_file_path.name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "\n",
    "    # Memgraph connection details from environment variables\n",
    "    memgraph_uri = os.getenv(\"MEMGRAPH_URI\", \"bolt://localhost:7687\")\n",
    "    memgraph_username = os.getenv(\"MEMGRAPH_USERNAME\", \"\")\n",
    "    memgraph_password = os.getenv(\"MEMGRAPH_PASSWORD\", \"\")\n",
    "\n",
    "    # Directory where your JSON files are stored\n",
    "    json_data_dir = Path(\"/Users/ryangichuru/Downloads/AI Group Project/other/resources/json_data\")\n",
    "\n",
    "    # --- Initialize Memgraph Connection ---\n",
    "    try:\n",
    "        print(f\"Connecting to Memgraph at {memgraph_uri}...\")\n",
    "        memgraph = MemgraphGraph(\n",
    "            url=memgraph_uri,\n",
    "            username=memgraph_username,\n",
    "            password=memgraph_password\n",
    "        )\n",
    "        # Optional: Test connection with a simple query\n",
    "        memgraph.query(\"RETURN 1\")\n",
    "        print(\"Memgraph connection successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Memgraph: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # --- Find and Process JSON Files ---\n",
    "    json_files = list(json_data_dir.glob('*.json'))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {json_data_dir}\")\n",
    "        exit(0)\n",
    "\n",
    "    print(f\"\\nFound {len(json_files)} JSON files to import.\")\n",
    "\n",
    "    for json_file in json_files:\n",
    "        import_json_to_memgraph(json_file, memgraph)\n",
    "\n",
    "    print(\"\\n--- Import Process Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
